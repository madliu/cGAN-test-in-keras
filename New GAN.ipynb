{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Dense, LSTM, Input, Reshape, merge\n",
    "import numpy as np\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.core import TimeDistributedDense\n",
    "import sys\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global _SESSION\n",
    "configtensor = tf.ConfigProto(allow_soft_placement=True)\n",
    "configtensor.gpu_options.allow_growth = True\n",
    "_SESSION = tf.Session(config=configtensor)\n",
    "K.set_session(_SESSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and testing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n"
     ]
    }
   ],
   "source": [
    "print ('Loading training data')\n",
    "inputFile  = \"/home/madli/Downloads/1. keras audio gan - audio-GAN-master/datasets/YourMusicLibraryNP\"\n",
    "X_train = np.load(inputFile + '_x.npy')\n",
    "Y_train = np.load(inputFile + '_y.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:100]\n",
    "Y_train = Y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape\n",
    "noise_train = np.random.random(input_shape) \n",
    "num_hidden_dimensions = 2\n",
    "sz=(X_train.shape[1], X_train.shape[2])\n",
    "n_epochs = 10 #What does this number do?\n",
    "batch_size = 20 #How many samples of generated and real audio are fed to the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining and testing the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generative_model(num_recurrent_units=1):\n",
    "    model = Sequential()\n",
    "    #This layer converts frequency space to hidden space\n",
    "    model.add( TimeDistributed( Dense( num_hidden_dimensions ), input_shape=sz ) )\n",
    "    for cur_unit in xrange(num_recurrent_units):\n",
    "        model.add(LSTM(input_dim=num_hidden_dimensions, output_dim=num_hidden_dimensions, return_sequences=True))\n",
    "    model.add(Dense(input_dim=num_hidden_dimensions, output_dim=num_hidden_dimensions)) #W_regularizer = l2(sys.argv[1])\n",
    "    #This layer converts hidden space back to frequency space\n",
    "    model.add(TimeDistributedDense(input_dim=num_hidden_dimensions, output_dim=X_train.shape[2]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_generative_model():\n",
    "    first_input = Input(shape=sz)\n",
    "    first_dense = Dense(output_dim=num_hidden_dimensions)(first_input)\n",
    "    \n",
    "    second_input = Input(shape = sz)\n",
    "    second_dense = Dense(output_dim=num_hidden_dimensions)(second_input)\n",
    "    \n",
    "    merge_one = merge([first_dense, second_dense], mode=\"concat\", concat_axis=2)\n",
    "    merge_one = Dense(output_dim=num_hidden_dimensions)(merge_one)\n",
    "    \n",
    "    lstm_out = LSTM(input_dim=num_hidden_dimensions, output_dim=num_hidden_dimensions, return_sequences=True)(first_dense)\n",
    "    third_dense = Dense(num_hidden_dimensions)(lstm_out)\n",
    "    outputs = TimeDistributedDense(X_train.shape[2])(second_dense)\n",
    "    model = Model(input=[first_input,second_input], output = outputs)\n",
    "    # Why four values after merging? Why can't change the output dimensions?\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madli/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:1206: UserWarning: `TimeDistributedDense` is deprecated, And will be removed on May 1st, 2017. Please use a `Dense` layer instead.\n",
      "  warnings.warn('`TimeDistributedDense` is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "generator = get_generative_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8, 4096)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "predictions2 = generator.predict (X_train)\n",
    "predictions2.shape\n",
    "#labelsdiscfalse = np.ones(predictionsdisc.shape, dtype=np.int) #predictionsdisc.shape asendada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s - loss: 0.0108     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: -0.0085     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: -0.0248     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: -0.0310     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: -0.0382     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: -0.0432     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: -0.0450     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: -0.0347     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: -0.0443     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: -0.0362        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 8, 4096)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "generator.fit(X_train, Y_train)\n",
    "predictions = generator.predict(X_train)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Defining and testing the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes in the concatenated input and outputs a value\n",
    "def get_disc_model():    \n",
    "    first_input = Input(shape=(sz[0],sz[1]*2))\n",
    "    first_dense = Dense(output_dim=3)(first_input)\n",
    "\n",
    "    second_input = Input(shape=sz)\n",
    "    second_dense = Dense(output_dim=3)(second_input)\n",
    "\n",
    "    merge_one = merge([first_dense, second_dense], mode=\"concat\", concat_axis=2)\n",
    "    merge_one = Dense(1, activation='sigmoid')(merge_one)\n",
    "    model = Model(input=[first_input,second_input], output = merge_one) #[first_input, second_input]\n",
    "    # Why four values after merging? Why can't change the output dimensions?\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_part = generator.predict(inputdata)\n",
    "inputdata = X_train[0*batch_size:(0+1)*batch_size]\n",
    "real_part = Y_train[0*batch_size:(0+1)*batch_size]\n",
    "real_pairs = np.concatenate((inputdata,real_part),axis=2) \n",
    "fake_pairs = np.concatenate((inputdata,fake_part),axis=2) \n",
    "labels = np.ones((10,8,1), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03053178  0.10942413  0.09317692 ..., -0.04423774 -0.22764404\n",
      "   0.003853  ]\n",
      " [-0.02000679  0.01765924 -0.25233278 ...,  0.09669302  0.32945899\n",
      "   0.06675315]\n",
      " [-0.10424472 -0.12149944 -0.2824247  ..., -0.32801883  0.35108975\n",
      "   0.04574882]\n",
      " ..., \n",
      " [ 0.47509923  0.37239508  0.1958198  ...,  0.03008591 -0.05190928\n",
      "   0.01690779]\n",
      " [-0.12812997 -0.07219134  0.72107097 ..., -0.25292542  0.13796815\n",
      "   0.21532358]\n",
      " [-0.23903382 -0.03900657  0.99542972 ...,  0.15476935 -0.07502141\n",
      "  -0.06414316]]\n",
      "other\n",
      "[[ 0.03053178  0.10942413  0.09317692 ...,  0.00880897 -0.00749003\n",
      "   0.00327377]\n",
      " [-0.02000679  0.01765924 -0.25233278 ...,  0.00924417 -0.0078593\n",
      "   0.00291241]\n",
      " [-0.10424472 -0.12149944 -0.2824247  ...,  0.00849269 -0.00813041\n",
      "   0.00255781]\n",
      " ..., \n",
      " [ 0.47509923  0.37239508  0.1958198  ...,  0.00819626 -0.00618548\n",
      "   0.00462747]\n",
      " [-0.12812997 -0.07219134  0.72107097 ...,  0.00958179 -0.00650731\n",
      "   0.00439645]\n",
      " [-0.23903382 -0.03900657  0.99542972 ...,  0.0095436  -0.00705654\n",
      "   0.00380183]]\n"
     ]
    }
   ],
   "source": [
    "print real_pairs[0]\n",
    "print \"other\"\n",
    "print fake_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s - loss: 0.9090 - acc: 0.5625\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s - loss: 0.5898 - acc: 0.6500\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s - loss: 0.5352 - acc: 0.7750\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s - loss: 0.5044 - acc: 0.8375\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s - loss: 0.4816 - acc: 0.8500\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s - loss: 0.4636 - acc: 0.8625\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s - loss: 0.4485 - acc: 0.8875\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s - loss: 0.4354 - acc: 0.9250\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s - loss: 0.4239 - acc: 0.9375\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s - loss: 0.4135 - acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 8, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = get_disc_model()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "discriminator.fit (real_pairs, labels)\n",
    "disc_predictions = discriminator.predict(real_pairs)\n",
    "disc_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator = get_disc_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Putting discriminator together with the generator\n",
    "\n",
    "Generator takes in a vector, transforms it into a vector with the same size. \n",
    "The output of the generator is concatenated with new vector of same size - resulting in a vector that is 2 as big.\n",
    "Discriminator takes an input that is 2 as big - concatenated parts\n",
    "Discriminator outputs 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    inputs = Input((8,4096))\n",
    "    x_generator = generator(inputs) #produces output that is shaped (100, 8, 4096)\n",
    "    \n",
    "    #takes the output produced by the generator and output and adds real input to the beginning\n",
    "    merged = merge([inputs, x_generator], mode='concat',concat_axis=2) \n",
    "    discriminator.trainable = False\n",
    "    x_discriminator = discriminator(merged)\n",
    "    \n",
    "    model = Model(input=inputs, output=[x_generator,x_discriminator])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator_containing_disciminator = generator_containing_discriminator(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[  7.71134626e-04,  -3.42320709e-05,  -8.03471310e-04, ...,\n",
       "            1.31508487e-03,   9.38146608e-04,   2.14764528e-04],\n",
       "         [ -2.01083021e-05,  -9.36924829e-04,  -9.88789019e-04, ...,\n",
       "           -1.47598970e-04,   1.88894453e-04,   5.01716626e-04],\n",
       "         [ -5.05514955e-03,   2.01874902e-03,   3.43254954e-03, ...,\n",
       "           -3.15271318e-03,  -4.60994430e-04,   7.57154450e-03],\n",
       "         ..., \n",
       "         [  3.73532041e-03,   8.03576689e-03,   4.12738789e-03, ...,\n",
       "           -2.80135125e-03,   6.67523942e-04,  -3.49254091e-03],\n",
       "         [  2.91457470e-03,   7.81282876e-03,   5.51034790e-03, ...,\n",
       "           -5.03126998e-03,  -1.75578543e-03,  -5.76267019e-03],\n",
       "         [  2.83952174e-03,   5.53051382e-03,   4.49369894e-03, ...,\n",
       "           -4.44472162e-03,  -1.99654605e-03,  -5.76119684e-03]],\n",
       " \n",
       "        [[ -1.84520846e-04,  -7.81183480e-05,   6.02692307e-04, ...,\n",
       "            8.97012942e-05,  -3.72854120e-04,  -2.18529531e-05],\n",
       "         [ -2.32931372e-04,   3.60343023e-04,   1.86788253e-04, ...,\n",
       "           -4.54675581e-04,   4.57221991e-04,   1.53250003e-04],\n",
       "         [  2.20746821e-04,   1.67747133e-03,   7.18661118e-04, ...,\n",
       "           -7.20785814e-04,   4.13128932e-04,  -2.99312611e-04],\n",
       "         ..., \n",
       "         [  1.16894051e-04,   5.12981205e-06,   4.37019567e-04, ...,\n",
       "            2.05661039e-04,  -1.76302245e-04,   2.82646739e-04],\n",
       "         [  1.01418619e-03,   1.04968858e-04,   2.24005693e-04, ...,\n",
       "            1.62807715e-04,  -2.07368983e-04,  -8.94012221e-04],\n",
       "         [ -6.10734976e-04,  -9.08139336e-04,   2.09089892e-04, ...,\n",
       "           -9.05603869e-04,  -8.52562662e-04,   8.37452128e-04]],\n",
       " \n",
       "        [[  2.02210480e-03,   1.85477547e-02,   1.23014282e-02, ...,\n",
       "           -9.21748765e-03,  -5.78399049e-03,  -7.36766309e-03],\n",
       "         [ -5.93451271e-03,   1.23261418e-02,   2.34550126e-02, ...,\n",
       "           -2.07556579e-02,  -2.28525065e-02,  -2.13701818e-02],\n",
       "         [ -7.02448934e-03,   4.82663028e-02,   2.17201505e-02, ...,\n",
       "            1.40063278e-03,  -2.08640900e-02,  -5.53412968e-03],\n",
       "         ..., \n",
       "         [  1.31327705e-03,  -2.44899970e-02,  -4.67435597e-03, ...,\n",
       "            1.93001498e-02,   7.35832052e-03,   8.30992125e-03],\n",
       "         [  3.13847116e-03,   4.31807805e-03,   1.07942130e-02, ...,\n",
       "           -2.39374526e-02,  -2.45966529e-03,  -2.37153731e-02],\n",
       "         [ -2.92421877e-02,  -6.65449211e-03,   7.94431102e-03, ...,\n",
       "           -1.67169832e-02,  -2.24351138e-03,   2.88845599e-02]],\n",
       " \n",
       "        ..., \n",
       "        [[ -4.23755322e-04,   7.71560182e-04,   9.82126105e-04, ...,\n",
       "           -5.07632329e-04,  -3.87478562e-04,  -1.36094488e-04],\n",
       "         [ -3.82855535e-04,   1.24070712e-03,   1.49261579e-03, ...,\n",
       "           -1.44224812e-03,  -4.06553241e-04,  -4.56922979e-04],\n",
       "         [  9.41196777e-05,   3.95200914e-04,   4.78917558e-04, ...,\n",
       "           -7.13183370e-04,   3.58045771e-04,  -4.76326735e-04],\n",
       "         ..., \n",
       "         [ -3.42385669e-04,  -4.09925240e-04,   1.48558000e-04, ...,\n",
       "           -6.63118786e-04,   1.21406047e-05,  -5.60582732e-04],\n",
       "         [ -9.87470848e-05,  -2.53629609e-04,   1.99126793e-04, ...,\n",
       "            3.32675991e-04,   6.59148965e-04,   6.35424294e-06],\n",
       "         [ -2.06143735e-03,   7.33400113e-04,   2.17166776e-03, ...,\n",
       "           -2.41700397e-03,  -8.43494083e-04,   1.36076950e-03]],\n",
       " \n",
       "        [[  9.57289885e-05,   4.04991268e-04,   4.82850824e-04, ...,\n",
       "           -1.28872890e-03,   7.64241558e-05,  -3.55944649e-04],\n",
       "         [  1.58716546e-04,  -2.00348964e-04,   5.28154720e-04, ...,\n",
       "           -1.94453890e-03,  -4.60854324e-04,  -1.32135546e-03],\n",
       "         [ -1.09780463e-03,   1.42833684e-03,   2.25543836e-03, ...,\n",
       "           -2.66039604e-03,  -1.23309274e-03,  -2.01805553e-04],\n",
       "         ..., \n",
       "         [ -1.07077928e-03,  -1.79345126e-03,   1.36842066e-03, ...,\n",
       "           -3.07948282e-03,  -2.15845625e-03,  -1.21845386e-03],\n",
       "         [ -1.04976492e-03,  -7.21337390e-04,   1.50444289e-03, ...,\n",
       "           -3.21895955e-03,  -1.53662392e-03,  -8.72933248e-04],\n",
       "         [ -1.76947180e-03,  -1.52162218e-03,   1.64268410e-03, ...,\n",
       "           -2.74855783e-03,  -2.34456081e-03,  -7.33792491e-04]],\n",
       " \n",
       "        [[  9.52114351e-05,   1.56307244e-04,  -1.00229285e-03, ...,\n",
       "           -1.70953991e-03,   4.36963572e-04,  -3.29205999e-04],\n",
       "         [ -3.50360619e-03,   1.08766719e-03,   3.84699693e-03, ...,\n",
       "           -6.32043928e-03,  -3.54050612e-03,  -1.02073303e-03],\n",
       "         [ -3.32568656e-03,   1.09402242e-03,   3.95479240e-03, ...,\n",
       "           -5.28581999e-03,  -3.00831790e-03,  -2.12555024e-04],\n",
       "         ..., \n",
       "         [ -2.65764864e-03,   1.25129533e-03,   3.74116842e-03, ...,\n",
       "           -3.66170099e-03,  -1.62385346e-03,   1.01785513e-03],\n",
       "         [ -2.55777407e-03,   1.03151193e-04,   2.58085434e-03, ...,\n",
       "           -2.45560217e-03,  -1.23266410e-03,   2.35312292e-03],\n",
       "         [ -2.97772652e-03,  -8.54472350e-03,  -3.35588073e-03, ...,\n",
       "           -6.86125737e-03,  -8.78752558e-04,   7.10831140e-04]]], dtype=float32),\n",
       " array([[[ 0.50863773],\n",
       "         [ 0.51677501],\n",
       "         [ 0.55844283],\n",
       "         [ 0.48592091],\n",
       "         [ 0.56624997],\n",
       "         [ 0.51260233],\n",
       "         [ 0.52411067],\n",
       "         [ 0.5471946 ]],\n",
       " \n",
       "        [[ 0.52139425],\n",
       "         [ 0.50943881],\n",
       "         [ 0.51709116],\n",
       "         [ 0.51757723],\n",
       "         [ 0.51643008],\n",
       "         [ 0.53037554],\n",
       "         [ 0.54183525],\n",
       "         [ 0.52183461]],\n",
       " \n",
       "        [[ 0.55780929],\n",
       "         [ 0.25985929],\n",
       "         [ 0.15235919],\n",
       "         [ 0.14819106],\n",
       "         [ 0.10501224],\n",
       "         [ 0.04062075],\n",
       "         [ 0.32132423],\n",
       "         [ 0.33347115]],\n",
       " \n",
       "        [[ 0.31648275],\n",
       "         [ 0.65297824],\n",
       "         [ 0.58074504],\n",
       "         [ 0.60544968],\n",
       "         [ 0.52930397],\n",
       "         [ 0.54990244],\n",
       "         [ 0.55666363],\n",
       "         [ 0.51175117]],\n",
       " \n",
       "        [[ 0.53814292],\n",
       "         [ 0.56388175],\n",
       "         [ 0.53009337],\n",
       "         [ 0.45486876],\n",
       "         [ 0.41441244],\n",
       "         [ 0.72983217],\n",
       "         [ 0.53807539],\n",
       "         [ 0.52193338]],\n",
       " \n",
       "        [[ 0.5318988 ],\n",
       "         [ 0.54883373],\n",
       "         [ 0.51419979],\n",
       "         [ 0.50414479],\n",
       "         [ 0.51395953],\n",
       "         [ 0.49853352],\n",
       "         [ 0.56807482],\n",
       "         [ 0.52193815]],\n",
       " \n",
       "        [[ 0.58567208],\n",
       "         [ 0.59116811],\n",
       "         [ 0.50437737],\n",
       "         [ 0.48787552],\n",
       "         [ 0.49442697],\n",
       "         [ 0.50712019],\n",
       "         [ 0.52041316],\n",
       "         [ 0.51476425]],\n",
       " \n",
       "        [[ 0.53893399],\n",
       "         [ 0.54007167],\n",
       "         [ 0.51963878],\n",
       "         [ 0.49986038],\n",
       "         [ 0.49071765],\n",
       "         [ 0.73025036],\n",
       "         [ 0.57710803],\n",
       "         [ 0.40514615]],\n",
       " \n",
       "        [[ 0.7043643 ],\n",
       "         [ 0.67017913],\n",
       "         [ 0.44357896],\n",
       "         [ 0.47109935],\n",
       "         [ 0.54616535],\n",
       "         [ 0.64246178],\n",
       "         [ 0.17174987],\n",
       "         [ 0.79472721]],\n",
       " \n",
       "        [[ 0.69167966],\n",
       "         [ 0.57947433],\n",
       "         [ 0.35476959],\n",
       "         [ 0.49166965],\n",
       "         [ 0.69507462],\n",
       "         [ 0.64760512],\n",
       "         [ 0.73654926],\n",
       "         [ 0.52961278]],\n",
       " \n",
       "        [[ 0.54823488],\n",
       "         [ 0.27220845],\n",
       "         [ 0.32557115],\n",
       "         [ 0.69083494],\n",
       "         [ 0.48598036],\n",
       "         [ 0.53331822],\n",
       "         [ 0.55665296],\n",
       "         [ 0.47617525]],\n",
       " \n",
       "        [[ 0.49056521],\n",
       "         [ 0.55674946],\n",
       "         [ 0.49673662],\n",
       "         [ 0.50545943],\n",
       "         [ 0.54481196],\n",
       "         [ 0.07605474],\n",
       "         [ 0.94230413],\n",
       "         [ 0.40087885]],\n",
       " \n",
       "        [[ 0.53900057],\n",
       "         [ 0.23172963],\n",
       "         [ 0.36991626],\n",
       "         [ 0.60316259],\n",
       "         [ 0.50488096],\n",
       "         [ 0.52377737],\n",
       "         [ 0.51830441],\n",
       "         [ 0.50844455]],\n",
       " \n",
       "        [[ 0.55496931],\n",
       "         [ 0.54015636],\n",
       "         [ 0.53329509],\n",
       "         [ 0.51504558],\n",
       "         [ 0.51462114],\n",
       "         [ 0.56862551],\n",
       "         [ 0.3632752 ],\n",
       "         [ 0.64341617]],\n",
       " \n",
       "        [[ 0.49282274],\n",
       "         [ 0.50313663],\n",
       "         [ 0.545138  ],\n",
       "         [ 0.49712473],\n",
       "         [ 0.54600245],\n",
       "         [ 0.51873362],\n",
       "         [ 0.49611458],\n",
       "         [ 0.52038687]],\n",
       " \n",
       "        [[ 0.53547591],\n",
       "         [ 0.49873155],\n",
       "         [ 0.51092601],\n",
       "         [ 0.53929698],\n",
       "         [ 0.53695816],\n",
       "         [ 0.49081388],\n",
       "         [ 0.51931727],\n",
       "         [ 0.52066278]],\n",
       " \n",
       "        [[ 0.59124726],\n",
       "         [ 0.50600499],\n",
       "         [ 0.51455325],\n",
       "         [ 0.52989727],\n",
       "         [ 0.62273103],\n",
       "         [ 0.54265523],\n",
       "         [ 0.49223086],\n",
       "         [ 0.51020479]],\n",
       " \n",
       "        [[ 0.53255868],\n",
       "         [ 0.53594303],\n",
       "         [ 0.53765482],\n",
       "         [ 0.51005602],\n",
       "         [ 0.5045976 ],\n",
       "         [ 0.53174645],\n",
       "         [ 0.49267015],\n",
       "         [ 0.52785033]],\n",
       " \n",
       "        [[ 0.52578223],\n",
       "         [ 0.50213325],\n",
       "         [ 0.46108839],\n",
       "         [ 0.47590652],\n",
       "         [ 0.55156016],\n",
       "         [ 0.51266712],\n",
       "         [ 0.50915152],\n",
       "         [ 0.50087255]],\n",
       " \n",
       "        [[ 0.51571864],\n",
       "         [ 0.50405622],\n",
       "         [ 0.90034676],\n",
       "         [ 0.61991519],\n",
       "         [ 0.46743828],\n",
       "         [ 0.4548147 ],\n",
       "         [ 0.54844415],\n",
       "         [ 0.55254191]],\n",
       " \n",
       "        [[ 0.5386647 ],\n",
       "         [ 0.53863424],\n",
       "         [ 0.518942  ],\n",
       "         [ 0.51925725],\n",
       "         [ 0.51398927],\n",
       "         [ 0.51355863],\n",
       "         [ 0.45382085],\n",
       "         [ 0.49191558]],\n",
       " \n",
       "        [[ 0.41883215],\n",
       "         [ 0.53794217],\n",
       "         [ 0.49916443],\n",
       "         [ 0.52507699],\n",
       "         [ 0.50352675],\n",
       "         [ 0.54802209],\n",
       "         [ 0.45599669],\n",
       "         [ 0.53058445]],\n",
       " \n",
       "        [[ 0.45033988],\n",
       "         [ 0.53870314],\n",
       "         [ 0.53310835],\n",
       "         [ 0.45267016],\n",
       "         [ 0.53402621],\n",
       "         [ 0.49228892],\n",
       "         [ 0.57194185],\n",
       "         [ 0.52638096]],\n",
       " \n",
       "        [[ 0.55207396],\n",
       "         [ 0.54708904],\n",
       "         [ 0.54475409],\n",
       "         [ 0.64596593],\n",
       "         [ 0.48408902],\n",
       "         [ 0.49796718],\n",
       "         [ 0.5317598 ],\n",
       "         [ 0.47008196]],\n",
       " \n",
       "        [[ 0.49847567],\n",
       "         [ 0.54459822],\n",
       "         [ 0.49831423],\n",
       "         [ 0.54416597],\n",
       "         [ 0.52391827],\n",
       "         [ 0.33505499],\n",
       "         [ 0.54888129],\n",
       "         [ 0.46872416]],\n",
       " \n",
       "        [[ 0.53372777],\n",
       "         [ 0.49896276],\n",
       "         [ 0.4921639 ],\n",
       "         [ 0.49118191],\n",
       "         [ 0.48396647],\n",
       "         [ 0.79371995],\n",
       "         [ 0.89632213],\n",
       "         [ 0.28795117]],\n",
       " \n",
       "        [[ 0.46278542],\n",
       "         [ 0.62179667],\n",
       "         [ 0.60208964],\n",
       "         [ 0.54771256],\n",
       "         [ 0.53418249],\n",
       "         [ 0.48786303],\n",
       "         [ 0.5216918 ],\n",
       "         [ 0.53349423]],\n",
       " \n",
       "        [[ 0.51912481],\n",
       "         [ 0.51314974],\n",
       "         [ 0.50465888],\n",
       "         [ 0.52723676],\n",
       "         [ 0.56539243],\n",
       "         [ 0.51336741],\n",
       "         [ 0.57065469],\n",
       "         [ 0.50530362]],\n",
       " \n",
       "        [[ 0.50125426],\n",
       "         [ 0.51974547],\n",
       "         [ 0.48459989],\n",
       "         [ 0.52885723],\n",
       "         [ 0.43682373],\n",
       "         [ 0.47455573],\n",
       "         [ 0.52945566],\n",
       "         [ 0.52621019]],\n",
       " \n",
       "        [[ 0.51880193],\n",
       "         [ 0.51088631],\n",
       "         [ 0.52038735],\n",
       "         [ 0.50973088],\n",
       "         [ 0.50956786],\n",
       "         [ 0.53148329],\n",
       "         [ 0.91593879],\n",
       "         [ 0.46285397]],\n",
       " \n",
       "        [[ 0.61590695],\n",
       "         [ 0.51169151],\n",
       "         [ 0.5082652 ],\n",
       "         [ 0.52103454],\n",
       "         [ 0.51745939],\n",
       "         [ 0.52147049],\n",
       "         [ 0.51708543],\n",
       "         [ 0.51810706]],\n",
       " \n",
       "        [[ 0.52270108],\n",
       "         [ 0.49752006],\n",
       "         [ 0.51051354],\n",
       "         [ 0.53169399],\n",
       "         [ 0.47925755],\n",
       "         [ 0.5075497 ],\n",
       "         [ 0.50611466],\n",
       "         [ 0.51690632]],\n",
       " \n",
       "        [[ 0.53943622],\n",
       "         [ 0.56451184],\n",
       "         [ 0.45058978],\n",
       "         [ 0.51769274],\n",
       "         [ 0.16796859],\n",
       "         [ 0.99967432],\n",
       "         [ 0.94134694],\n",
       "         [ 0.00194804]],\n",
       " \n",
       "        [[ 0.09169179],\n",
       "         [ 0.4644891 ],\n",
       "         [ 0.47506353],\n",
       "         [ 0.0116933 ],\n",
       "         [ 0.29173371],\n",
       "         [ 0.27124381],\n",
       "         [ 0.3873128 ],\n",
       "         [ 0.5283848 ]],\n",
       " \n",
       "        [[ 0.53570884],\n",
       "         [ 0.53105724],\n",
       "         [ 0.42084271],\n",
       "         [ 0.99919802],\n",
       "         [ 0.72812313],\n",
       "         [ 0.52140462],\n",
       "         [ 0.23217112],\n",
       "         [ 0.7694661 ]],\n",
       " \n",
       "        [[ 0.44924065],\n",
       "         [ 0.50172263],\n",
       "         [ 0.49955931],\n",
       "         [ 0.55298233],\n",
       "         [ 0.52743602],\n",
       "         [ 0.46783891],\n",
       "         [ 0.57851696],\n",
       "         [ 0.46462041]],\n",
       " \n",
       "        [[ 0.53002125],\n",
       "         [ 0.49841425],\n",
       "         [ 0.55061185],\n",
       "         [ 0.5190298 ],\n",
       "         [ 0.52421325],\n",
       "         [ 0.75836539],\n",
       "         [ 0.38249013],\n",
       "         [ 0.49281892]],\n",
       " \n",
       "        [[ 0.60605538],\n",
       "         [ 0.51050484],\n",
       "         [ 0.50859475],\n",
       "         [ 0.52157557],\n",
       "         [ 0.50328416],\n",
       "         [ 0.50384951],\n",
       "         [ 0.53020728],\n",
       "         [ 0.50472897]],\n",
       " \n",
       "        [[ 0.53979415],\n",
       "         [ 0.50595015],\n",
       "         [ 0.51633972],\n",
       "         [ 0.5167011 ],\n",
       "         [ 0.53618622],\n",
       "         [ 0.52282107],\n",
       "         [ 0.47067216],\n",
       "         [ 0.48024026]],\n",
       " \n",
       "        [[ 0.55278718],\n",
       "         [ 0.5277552 ],\n",
       "         [ 0.51287031],\n",
       "         [ 0.51515198],\n",
       "         [ 0.51251906],\n",
       "         [ 0.56202412],\n",
       "         [ 0.64447236],\n",
       "         [ 0.56707972]],\n",
       " \n",
       "        [[ 0.51327449],\n",
       "         [ 0.51377767],\n",
       "         [ 0.64339906],\n",
       "         [ 0.42057011],\n",
       "         [ 0.52014261],\n",
       "         [ 0.53214616],\n",
       "         [ 0.42174056],\n",
       "         [ 0.54281616]],\n",
       " \n",
       "        [[ 0.46197048],\n",
       "         [ 0.50105864],\n",
       "         [ 0.34153834],\n",
       "         [ 0.9445973 ],\n",
       "         [ 0.59594536],\n",
       "         [ 0.21293698],\n",
       "         [ 0.55711734],\n",
       "         [ 0.51372755]],\n",
       " \n",
       "        [[ 0.50178909],\n",
       "         [ 0.5203492 ],\n",
       "         [ 0.50257868],\n",
       "         [ 0.49409392],\n",
       "         [ 0.52992433],\n",
       "         [ 0.52165705],\n",
       "         [ 0.51835173],\n",
       "         [ 0.5052799 ]],\n",
       " \n",
       "        [[ 0.50457293],\n",
       "         [ 0.51614159],\n",
       "         [ 0.51275015],\n",
       "         [ 0.49532732],\n",
       "         [ 0.51208234],\n",
       "         [ 0.54150641],\n",
       "         [ 0.52997279],\n",
       "         [ 0.53100932]],\n",
       " \n",
       "        [[ 0.52151316],\n",
       "         [ 0.4159838 ],\n",
       "         [ 0.5971632 ],\n",
       "         [ 0.41054547],\n",
       "         [ 0.52929521],\n",
       "         [ 0.47276896],\n",
       "         [ 0.50144929],\n",
       "         [ 0.52647406]],\n",
       " \n",
       "        [[ 0.49665594],\n",
       "         [ 0.49085706],\n",
       "         [ 0.51439434],\n",
       "         [ 0.53431362],\n",
       "         [ 0.52004659],\n",
       "         [ 0.51429856],\n",
       "         [ 0.56136537],\n",
       "         [ 0.61193788]],\n",
       " \n",
       "        [[ 0.54107028],\n",
       "         [ 0.51029825],\n",
       "         [ 0.52152801],\n",
       "         [ 0.51116008],\n",
       "         [ 0.52008796],\n",
       "         [ 0.49772692],\n",
       "         [ 0.52106661],\n",
       "         [ 0.49847105]],\n",
       " \n",
       "        [[ 0.52241838],\n",
       "         [ 0.43572226],\n",
       "         [ 0.52013475],\n",
       "         [ 0.48931083],\n",
       "         [ 0.51585788],\n",
       "         [ 0.50088376],\n",
       "         [ 0.52806538],\n",
       "         [ 0.54138851]],\n",
       " \n",
       "        [[ 0.53060412],\n",
       "         [ 0.51153821],\n",
       "         [ 0.3254872 ],\n",
       "         [ 0.80417538],\n",
       "         [ 0.53519732],\n",
       "         [ 0.49248931],\n",
       "         [ 0.50994945],\n",
       "         [ 0.47464886]],\n",
       " \n",
       "        [[ 0.56472343],\n",
       "         [ 0.50648344],\n",
       "         [ 0.57880259],\n",
       "         [ 0.51328325],\n",
       "         [ 0.56755   ],\n",
       "         [ 0.55218869],\n",
       "         [ 0.52236539],\n",
       "         [ 0.5747714 ]],\n",
       " \n",
       "        [[ 0.52207404],\n",
       "         [ 0.44314992],\n",
       "         [ 0.44713575],\n",
       "         [ 0.49589798],\n",
       "         [ 0.51396602],\n",
       "         [ 0.53985381],\n",
       "         [ 0.49979451],\n",
       "         [ 0.52477843]],\n",
       " \n",
       "        [[ 0.52214348],\n",
       "         [ 0.4933835 ],\n",
       "         [ 0.47910136],\n",
       "         [ 0.42936864],\n",
       "         [ 0.48427266],\n",
       "         [ 0.48357609],\n",
       "         [ 0.49310231],\n",
       "         [ 0.50684029]],\n",
       " \n",
       "        [[ 0.50198644],\n",
       "         [ 0.55390608],\n",
       "         [ 0.478643  ],\n",
       "         [ 0.4794459 ],\n",
       "         [ 0.49975109],\n",
       "         [ 0.51577282],\n",
       "         [ 0.52741122],\n",
       "         [ 0.37792256]],\n",
       " \n",
       "        [[ 0.74175286],\n",
       "         [ 0.56972909],\n",
       "         [ 0.49267101],\n",
       "         [ 0.51319242],\n",
       "         [ 0.49958888],\n",
       "         [ 0.42741945],\n",
       "         [ 0.43042523],\n",
       "         [ 0.52675253]],\n",
       " \n",
       "        [[ 0.49042892],\n",
       "         [ 0.54702318],\n",
       "         [ 0.69868809],\n",
       "         [ 0.61795533],\n",
       "         [ 0.60957873],\n",
       "         [ 0.59068888],\n",
       "         [ 0.34596992],\n",
       "         [ 0.67995733]],\n",
       " \n",
       "        [[ 0.55094481],\n",
       "         [ 0.36041051],\n",
       "         [ 0.4234305 ],\n",
       "         [ 0.51481611],\n",
       "         [ 0.53855664],\n",
       "         [ 0.49749705],\n",
       "         [ 0.55911708],\n",
       "         [ 0.54047495]],\n",
       " \n",
       "        [[ 0.49207798],\n",
       "         [ 0.53479862],\n",
       "         [ 0.52826482],\n",
       "         [ 0.51586431],\n",
       "         [ 0.55755001],\n",
       "         [ 0.54322541],\n",
       "         [ 0.51414174],\n",
       "         [ 0.56201571]],\n",
       " \n",
       "        [[ 0.49654549],\n",
       "         [ 0.65286708],\n",
       "         [ 0.50572091],\n",
       "         [ 0.53623968],\n",
       "         [ 0.52202111],\n",
       "         [ 0.5258891 ],\n",
       "         [ 0.51327664],\n",
       "         [ 0.51243281]],\n",
       " \n",
       "        [[ 0.50418007],\n",
       "         [ 0.51994741],\n",
       "         [ 0.49911898],\n",
       "         [ 0.51186079],\n",
       "         [ 0.51380402],\n",
       "         [ 0.5253008 ],\n",
       "         [ 0.53038085],\n",
       "         [ 0.52543819]],\n",
       " \n",
       "        [[ 0.52780139],\n",
       "         [ 0.47534031],\n",
       "         [ 0.4999218 ],\n",
       "         [ 0.505422  ],\n",
       "         [ 0.51068228],\n",
       "         [ 0.48880959],\n",
       "         [ 0.51647645],\n",
       "         [ 0.51999009]],\n",
       " \n",
       "        [[ 0.72267383],\n",
       "         [ 0.95260543],\n",
       "         [ 0.46174884],\n",
       "         [ 0.57704556],\n",
       "         [ 0.46708798],\n",
       "         [ 0.54609644],\n",
       "         [ 0.57717639],\n",
       "         [ 0.52439088]],\n",
       " \n",
       "        [[ 0.49363825],\n",
       "         [ 0.49770308],\n",
       "         [ 0.52309215],\n",
       "         [ 0.53792709],\n",
       "         [ 0.48117349],\n",
       "         [ 0.48056966],\n",
       "         [ 0.5287571 ],\n",
       "         [ 0.52244103]],\n",
       " \n",
       "        [[ 0.43672812],\n",
       "         [ 0.50978822],\n",
       "         [ 0.58766115],\n",
       "         [ 0.55876446],\n",
       "         [ 0.53151411],\n",
       "         [ 0.51273823],\n",
       "         [ 0.50474906],\n",
       "         [ 0.51534688]],\n",
       " \n",
       "        [[ 0.52445149],\n",
       "         [ 0.51977801],\n",
       "         [ 0.6614266 ],\n",
       "         [ 0.06237388],\n",
       "         [ 0.71103442],\n",
       "         [ 0.62945038],\n",
       "         [ 0.52463007],\n",
       "         [ 0.50625461]],\n",
       " \n",
       "        [[ 0.6334762 ],\n",
       "         [ 0.59619147],\n",
       "         [ 0.38574138],\n",
       "         [ 0.80871803],\n",
       "         [ 0.50918049],\n",
       "         [ 0.53955466],\n",
       "         [ 0.4593218 ],\n",
       "         [ 0.51773506]],\n",
       " \n",
       "        [[ 0.51459438],\n",
       "         [ 0.53336853],\n",
       "         [ 0.47960949],\n",
       "         [ 0.51283866],\n",
       "         [ 0.53323239],\n",
       "         [ 0.51727778],\n",
       "         [ 0.50502366],\n",
       "         [ 0.52481174]],\n",
       " \n",
       "        [[ 0.53234547],\n",
       "         [ 0.22199848],\n",
       "         [ 0.56276828],\n",
       "         [ 0.53928733],\n",
       "         [ 0.5372442 ],\n",
       "         [ 0.53136075],\n",
       "         [ 0.50957096],\n",
       "         [ 0.49392647]],\n",
       " \n",
       "        [[ 0.54406321],\n",
       "         [ 0.53928304],\n",
       "         [ 0.50879306],\n",
       "         [ 0.51285356],\n",
       "         [ 0.53051174],\n",
       "         [ 0.51198936],\n",
       "         [ 0.54276937],\n",
       "         [ 0.49856836]],\n",
       " \n",
       "        [[ 0.5035094 ],\n",
       "         [ 0.55676579],\n",
       "         [ 0.4907583 ],\n",
       "         [ 0.51455706],\n",
       "         [ 0.51483989],\n",
       "         [ 0.49439445],\n",
       "         [ 0.44647565],\n",
       "         [ 0.38968322]],\n",
       " \n",
       "        [[ 0.54080093],\n",
       "         [ 0.57404155],\n",
       "         [ 0.01605136],\n",
       "         [ 0.88594973],\n",
       "         [ 0.47545266],\n",
       "         [ 0.48136008],\n",
       "         [ 0.51037478],\n",
       "         [ 0.51296997]],\n",
       " \n",
       "        [[ 0.51236176],\n",
       "         [ 0.48203272],\n",
       "         [ 0.51302677],\n",
       "         [ 0.52108043],\n",
       "         [ 0.51778615],\n",
       "         [ 0.51057547],\n",
       "         [ 0.523399  ],\n",
       "         [ 0.51974177]],\n",
       " \n",
       "        [[ 0.50872219],\n",
       "         [ 0.5059067 ],\n",
       "         [ 0.51008821],\n",
       "         [ 0.51156038],\n",
       "         [ 0.49894151],\n",
       "         [ 0.22640178],\n",
       "         [ 0.41032431],\n",
       "         [ 0.59851342]],\n",
       " \n",
       "        [[ 0.48874334],\n",
       "         [ 0.49711329],\n",
       "         [ 0.56836033],\n",
       "         [ 0.50054175],\n",
       "         [ 0.49190208],\n",
       "         [ 0.56988305],\n",
       "         [ 0.50536704],\n",
       "         [ 0.55280745]],\n",
       " \n",
       "        [[ 0.48064968],\n",
       "         [ 0.52870238],\n",
       "         [ 0.44587189],\n",
       "         [ 0.74806219],\n",
       "         [ 0.94597846],\n",
       "         [ 0.08743173],\n",
       "         [ 0.42754337],\n",
       "         [ 0.68643415]],\n",
       " \n",
       "        [[ 0.92082864],\n",
       "         [ 0.52953708],\n",
       "         [ 0.47040951],\n",
       "         [ 0.60144848],\n",
       "         [ 0.52865553],\n",
       "         [ 0.53570485],\n",
       "         [ 0.37953624],\n",
       "         [ 0.50349188]],\n",
       " \n",
       "        [[ 0.50535238],\n",
       "         [ 0.55548155],\n",
       "         [ 0.44419447],\n",
       "         [ 0.58718979],\n",
       "         [ 0.55142826],\n",
       "         [ 0.50879115],\n",
       "         [ 0.52710778],\n",
       "         [ 0.53818911]],\n",
       " \n",
       "        [[ 0.52432382],\n",
       "         [ 0.53511429],\n",
       "         [ 0.49244016],\n",
       "         [ 0.54139781],\n",
       "         [ 0.44161674],\n",
       "         [ 0.50665003],\n",
       "         [ 0.52661121],\n",
       "         [ 0.50341988]],\n",
       " \n",
       "        [[ 0.52550918],\n",
       "         [ 0.51787853],\n",
       "         [ 0.43013027],\n",
       "         [ 0.19170199],\n",
       "         [ 0.28141269],\n",
       "         [ 0.23116413],\n",
       "         [ 0.01405213],\n",
       "         [ 0.93346518]],\n",
       " \n",
       "        [[ 0.07552055],\n",
       "         [ 0.09816551],\n",
       "         [ 0.90715379],\n",
       "         [ 0.90476495],\n",
       "         [ 0.50958455],\n",
       "         [ 0.51655793],\n",
       "         [ 0.58299917],\n",
       "         [ 0.58181745]],\n",
       " \n",
       "        [[ 0.54489821],\n",
       "         [ 0.48980784],\n",
       "         [ 0.56680542],\n",
       "         [ 0.51800036],\n",
       "         [ 0.50662142],\n",
       "         [ 0.54139197],\n",
       "         [ 0.63798195],\n",
       "         [ 0.81581819]],\n",
       " \n",
       "        [[ 0.3568581 ],\n",
       "         [ 0.50747222],\n",
       "         [ 0.00116625],\n",
       "         [ 0.00430055],\n",
       "         [ 0.5088954 ],\n",
       "         [ 0.55017364],\n",
       "         [ 0.570454  ],\n",
       "         [ 0.53052461]],\n",
       " \n",
       "        [[ 0.56159621],\n",
       "         [ 0.52316254],\n",
       "         [ 0.50425482],\n",
       "         [ 0.36969978],\n",
       "         [ 0.08178516],\n",
       "         [ 0.84516585],\n",
       "         [ 0.38709939],\n",
       "         [ 0.53502649]],\n",
       " \n",
       "        [[ 0.48294434],\n",
       "         [ 0.51734769],\n",
       "         [ 0.52942502],\n",
       "         [ 0.58828998],\n",
       "         [ 0.61149901],\n",
       "         [ 0.40671206],\n",
       "         [ 0.55373961],\n",
       "         [ 0.5049957 ]],\n",
       " \n",
       "        [[ 0.63590622],\n",
       "         [ 0.45831653],\n",
       "         [ 0.4915244 ],\n",
       "         [ 0.51928282],\n",
       "         [ 0.53138715],\n",
       "         [ 0.52827829],\n",
       "         [ 0.53092343],\n",
       "         [ 0.53680384]],\n",
       " \n",
       "        [[ 0.51911688],\n",
       "         [ 0.58080494],\n",
       "         [ 0.52816212],\n",
       "         [ 0.96234208],\n",
       "         [ 0.45033383],\n",
       "         [ 0.54648042],\n",
       "         [ 0.53284013],\n",
       "         [ 0.51875222]],\n",
       " \n",
       "        [[ 0.55053008],\n",
       "         [ 0.45591748],\n",
       "         [ 0.53254443],\n",
       "         [ 0.51073498],\n",
       "         [ 0.45741826],\n",
       "         [ 0.50309908],\n",
       "         [ 0.57836866],\n",
       "         [ 0.5196867 ]],\n",
       " \n",
       "        [[ 0.59261847],\n",
       "         [ 0.50052381],\n",
       "         [ 0.44070569],\n",
       "         [ 0.58308703],\n",
       "         [ 0.57952505],\n",
       "         [ 0.55967933],\n",
       "         [ 0.52547687],\n",
       "         [ 0.50495726]],\n",
       " \n",
       "        [[ 0.4208447 ],\n",
       "         [ 0.49917299],\n",
       "         [ 0.52252132],\n",
       "         [ 0.49800906],\n",
       "         [ 0.51524419],\n",
       "         [ 0.47261915],\n",
       "         [ 0.49613094],\n",
       "         [ 0.52788031]],\n",
       " \n",
       "        [[ 0.49649906],\n",
       "         [ 1.        ],\n",
       "         [ 0.00204142],\n",
       "         [ 0.99997795],\n",
       "         [ 0.01240135],\n",
       "         [ 0.3033019 ],\n",
       "         [ 0.03034613],\n",
       "         [ 0.3542937 ]],\n",
       " \n",
       "        [[ 0.55260581],\n",
       "         [ 0.43229216],\n",
       "         [ 0.46928319],\n",
       "         [ 0.40974486],\n",
       "         [ 0.93080866],\n",
       "         [ 0.66289634],\n",
       "         [ 0.35082662],\n",
       "         [ 0.91705406]],\n",
       " \n",
       "        [[ 0.99345618],\n",
       "         [ 0.43723041],\n",
       "         [ 0.48609751],\n",
       "         [ 0.55904156],\n",
       "         [ 0.47511202],\n",
       "         [ 0.53296345],\n",
       "         [ 0.49719945],\n",
       "         [ 0.52910084]],\n",
       " \n",
       "        [[ 0.5052014 ],\n",
       "         [ 0.4772341 ],\n",
       "         [ 0.68259239],\n",
       "         [ 0.32124242],\n",
       "         [ 0.51181656],\n",
       "         [ 0.51309055],\n",
       "         [ 0.49937868],\n",
       "         [ 0.4694705 ]],\n",
       " \n",
       "        [[ 0.44191179],\n",
       "         [ 0.43106583],\n",
       "         [ 0.5809924 ],\n",
       "         [ 0.49779597],\n",
       "         [ 0.51245368],\n",
       "         [ 0.5084579 ],\n",
       "         [ 0.57964206],\n",
       "         [ 0.47124934]],\n",
       " \n",
       "        [[ 0.52572542],\n",
       "         [ 0.50530553],\n",
       "         [ 0.52057666],\n",
       "         [ 0.49479347],\n",
       "         [ 0.45758903],\n",
       "         [ 0.68946218],\n",
       "         [ 0.61117727],\n",
       "         [ 0.40840364]],\n",
       " \n",
       "        [[ 0.47633436],\n",
       "         [ 0.45177811],\n",
       "         [ 0.52187032],\n",
       "         [ 0.52665979],\n",
       "         [ 0.51492745],\n",
       "         [ 0.51474518],\n",
       "         [ 0.5278669 ],\n",
       "         [ 0.51720196]],\n",
       " \n",
       "        [[ 0.49362797],\n",
       "         [ 0.7123338 ],\n",
       "         [ 0.57030147],\n",
       "         [ 0.95505369],\n",
       "         [ 0.19776943],\n",
       "         [ 0.6416679 ],\n",
       "         [ 0.53319788],\n",
       "         [ 0.60419196]],\n",
       " \n",
       "        [[ 0.52296644],\n",
       "         [ 0.50443929],\n",
       "         [ 0.53835684],\n",
       "         [ 0.45464936],\n",
       "         [ 0.51164144],\n",
       "         [ 0.52014762],\n",
       "         [ 0.52409852],\n",
       "         [ 0.53019404]],\n",
       " \n",
       "        [[ 0.51654947],\n",
       "         [ 0.52060384],\n",
       "         [ 0.50068104],\n",
       "         [ 0.5209778 ],\n",
       "         [ 0.51941705],\n",
       "         [ 0.5300926 ],\n",
       "         [ 0.52037537],\n",
       "         [ 0.53326571]],\n",
       " \n",
       "        [[ 0.517111  ],\n",
       "         [ 0.52614528],\n",
       "         [ 0.5048539 ],\n",
       "         [ 0.51754588],\n",
       "         [ 0.51476228],\n",
       "         [ 0.50368899],\n",
       "         [ 0.50195086],\n",
       "         [ 0.5077157 ]],\n",
       " \n",
       "        [[ 0.50688994],\n",
       "         [ 0.46649188],\n",
       "         [ 0.5305028 ],\n",
       "         [ 0.51855063],\n",
       "         [ 0.5108338 ],\n",
       "         [ 0.51245356],\n",
       "         [ 0.50671107],\n",
       "         [ 0.39818525]]], dtype=float32)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = generator_containing_disciminator.predict(X_train)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def get_generator_containing_disciminator():\n",
    "    first_input = Input(shape=sz)\n",
    "    first_dense = Dense(output_dim=num_hidden_dimensions)(first_input)\n",
    "    lstm_out = LSTM(input_dim=num_hidden_dimensions, output_dim=num_hidden_dimensions, return_sequences=True)(first_dense)\n",
    "    second_dense = Dense(num_hidden_dimensions)(lstm_out)\n",
    "    outputs = TimeDistributedDense(X_train.shape[2])(second_dense)\n",
    "\n",
    "    second_input = outputs\n",
    "    first_dense = Dense(output_dim=3)(second_input)\n",
    "\n",
    "    third_input = Input(shape=sz)\n",
    "    second_dense = Dense(output_dim=3)(third_input)\n",
    "\n",
    "    merge_one = merge([first_dense, second_dense]) #mode=\"concat\", concat_axis=1\n",
    "    merge_one = Dense(1, activation='sigmoid')(merge_one)\n",
    "    model = Model(input=[first_input, third_input], output = merge_one)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#genanddisc = generator_containing_discriminator(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def get_generator_containing_disciminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generator_containing_disciminator = get_generator_containing_disciminator(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-43-3c9b11ca62c1>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-3c9b11ca62c1>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    #GAN.summary()\u001b[0m\n\u001b[0m                  \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "first_input = Input(shape=sz)\n",
    "first_layer = generator(first_input)\n",
    "second_input = first_layer\n",
    "\n",
    "third_input= Input(shape=sz)\n",
    "second_layer = discriminator(first_layer)\n",
    "model = Model(input=first_input, output = second_layer)\n",
    "\n",
    "gan_input = Input(shape=sz)\n",
    "H = generator(gan_input)\n",
    "gan_V = discriminator(H)\n",
    "GAN = Model(gan_input, gan_V)\n",
    "#GAN.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "#GAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Setting optimization parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "generator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "generator_containing_disciminator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Get total number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches = int(len(X_train)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Get losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "def get_losses(i):\n",
    "    print ('Epoch:', i+1)\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for index in range(n_batches):\n",
    "        # 9.1 Get generated samples according to the batch size number\n",
    "        inputdata = X_train[index*batch_size:(index+1)*batch_size]\n",
    "        noise = np.random.random(inputdata.shape)\n",
    "        generated_part = generator.predict(inputdata)\n",
    "        real_part = Y_train[index*batch_size:(index+1)*batch_size]\n",
    "        real_pairs = np.concatenate((inputdata,real_part),axis=2)  #maybe not necessary since discriminator takes 2 inputs anyway\n",
    "        fake_pairs = np.concatenate((inputdata,generated_part),axis=2)\n",
    "        X = np.concatenate((real_pairs,fake_pairs))\n",
    "        #print X.shape\n",
    "        real_labels = np.ones((batch_size,X_train.shape[1],1))\n",
    "        fake_labels = np.zeros((batch_size,X_train.shape[1],1))\n",
    "        y = np.concatenate((real_labels,fake_labels),axis=0)\n",
    "        #print y\n",
    "        d_loss = discriminator.train_on_batch(X, y) # why does this output 2 numbers???\n",
    "        #print discriminator.metrics_names\n",
    "        d_losses.append(d_loss)\n",
    "        #print d_loss\n",
    "        pred_temp = discriminator.predict(X)\n",
    "        #print pred_temp\n",
    "        discriminator.trainable = False\n",
    "        #print inputdata.shape\n",
    "        \n",
    "        g_loss = generator_containing_disciminator.train_on_batch(inputdata, [real_part,real_labels] )\n",
    "        g_losses.append(g_loss)\n",
    "        #print generator_containing_disciminator.metrics_names\n",
    "        #print g_loss\n",
    "        #print(\"batch %d g_loss : %f\" % (index, g_loss[1]))\n",
    "        discriminator.trainable = True\n",
    "        if index % 10 == 0:\n",
    "                generator.save_weights('generator'+str(index), True)\n",
    "                discriminator.save_weights('discriminator'+str(index), True)     \n",
    "    \n",
    "    \n",
    "            # Print how many batches have been trained on \n",
    "        sys.stdout.write(' + batch: ' + str(index+1) + '/' + str(n_batches) + '\\r')\n",
    "        # Everything from the buffer will be written in the terminal \n",
    "        sys.stdout.flush()\n",
    "    i += 1\n",
    "    return d_losses, g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-790c8634d56b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0md_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmean_dloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmean_gloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m## REMOVE \\N if it is not necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):   \n",
    "    d_losses, g_losses = get_losses(i)\n",
    "    mean_dloss = round(np.mean(d_losses), 2)\n",
    "    mean_gloss = round(np.mean(g_losses), 2)\n",
    "    ## REMOVE \\N if it is not necessary \n",
    "    print ('\\n + d_loss:', mean_dloss)\n",
    "    print (' + g_loss:', mean_gloss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
