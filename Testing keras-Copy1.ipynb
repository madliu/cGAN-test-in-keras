{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Dense, LSTM, Input, Reshape, merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading input data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[0.2 , 0.3, 0.4, 0.5], [0.3, 0.4, 0.5, 0.6], [0.2, 0.2, 0.3, 0.3]])\n",
    "Y = np.array([[0.3, 0.4, 0.5, 0.6], [0.4, 0.5, 0.6, 0.7], [0.3, 0.3, 0.3, 0.3]])\n",
    "noise = np.random.random((3, 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = np.array([0.5, 0.2, 0.3, 0.5])\n",
    "new_data = np.reshape(new_data, (1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining the generator and the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try out different numbers of output dimensions\n",
    "def get_generative_model(input_dim = 4, num_recurrent_units = 1):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='relu', input_dim = 4))\n",
    "    predicted = model.add(Dense(4, activation='sigmoid'))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.37064004]\n",
      " [-0.8000145 ]\n",
      " [ 0.82944107]\n",
      " [ 1.02208614]]\n",
      "biases\n",
      "[ 0.]\n",
      "[[ 0.53198922  0.35238305  0.52333963  0.47842318]\n",
      " [ 0.53868514  0.32378441  0.52823347  0.47389776]\n",
      " [ 0.52220607  0.39599964  0.51619643  0.48502773]]\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s - loss: 0.6997\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s - loss: 0.6991\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s - loss: 0.6986\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s - loss: 0.6982\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s - loss: 0.6979\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s - loss: 0.6976\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s - loss: 0.6973\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s - loss: 0.6971\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s - loss: 0.6969\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s - loss: 0.6966\n",
      "[array([[ 0.35400149],\n",
      "       [-0.81670916],\n",
      "       [ 0.81278151],\n",
      "       [ 1.00539446]], dtype=float32), array([-0.01651869], dtype=float32), array([[ 0.17227678, -0.88255495,  0.12190157, -0.110672  ]], dtype=float32), array([-0.01719908,  0.01614826, -0.01687443,  0.01685905], dtype=float32)]\n",
      "[[ 0.35400149]\n",
      " [-0.81670916]\n",
      " [ 0.81278151]\n",
      " [ 1.00539446]]\n",
      "biases\n",
      "[-0.01651869]\n",
      "[[ 0.52312219  0.3667677   0.51519191  0.48659128]\n",
      " [ 0.52894419  0.33945227  0.51931787  0.4828445 ]\n",
      " [ 0.51449126  0.4087846   0.50907964  0.49214134]]\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s - loss: 0.6964\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s - loss: 0.6959\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s - loss: 0.6955\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s - loss: 0.6952\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s - loss: 0.6949\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s - loss: 0.6947\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s - loss: 0.6944\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s - loss: 0.6942\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s - loss: 0.6940\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s - loss: 0.6939\n",
      "[array([[ 0.3375155 ],\n",
      "       [-0.83327997],\n",
      "       [ 0.79626369],\n",
      "       [ 0.98882848]], dtype=float32), array([-0.03280776], dtype=float32), array([[ 0.15528598, -0.86629176,  0.10628743, -0.09378393]], dtype=float32), array([-0.03439735,  0.03155428, -0.03369332,  0.03365419], dtype=float32)]\n",
      "[[ 0.3375155 ]\n",
      " [-0.83327997]\n",
      " [ 0.79626369]\n",
      " [ 0.98882848]]\n",
      "biases\n",
      "[-0.03280776]\n",
      "[[ 0.51459742  0.38079658  0.5074563   0.49440172]\n",
      " [ 0.51959693  0.35483298  0.51088113  0.49137941]\n",
      " [ 0.50706726  0.42115048  0.5023002   0.49895149]]\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s - loss: 0.6937\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s - loss: 0.6929\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s - loss: 0.6927\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s - loss: 0.6924\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s - loss: 0.6922\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s - loss: 0.6921\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s - loss: 0.6919\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s - loss: 0.6917\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s - loss: 0.6916\n",
      "[array([[ 0.3211911 ],\n",
      "       [-0.84973609],\n",
      "       [ 0.77988887],\n",
      "       [ 0.97237945]], dtype=float32), array([-0.04878638], dtype=float32), array([[ 0.13830855, -0.85031801,  0.09206767, -0.07690981]], dtype=float32), array([-0.05159504,  0.04393395, -0.05044646,  0.05036308], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "generator = get_generative_model()\n",
    "\n",
    "for i in range(3):\n",
    "    weights = generator.layers[0].get_weights()[0]\n",
    "    biases = generator.layers[0].get_weights()[1]\n",
    "    print weights\n",
    "    print \"biases\"\n",
    "    print biases\n",
    "\n",
    "    generator.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "    predictions = generator.predict(X)\n",
    "    print predictions\n",
    "    generator.fit(X, Y)\n",
    "    weights2 = generator.get_weights()\n",
    "    print weights2\n",
    "\n",
    "#generator.predict(Xwithnoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.21257015, -0.39053315, -0.39324281],\n",
       "        [ 0.58025825,  0.15116811, -0.88164705],\n",
       "        [ 0.66209418, -0.39955997, -0.14333114],\n",
       "        [-0.40137407, -0.56507242,  0.90970021]], dtype=float32),\n",
       " array([-0.00760559,  0.        ,  0.00154553], dtype=float32),\n",
       " array([[ 0.84257764,  0.76163155,  0.48641929,  0.00907715],\n",
       "        [ 0.19483352, -0.68577266, -0.69406331,  0.44337165],\n",
       "        [-0.43028358, -0.90869778,  0.48243687, -0.50956267]], dtype=float32),\n",
       " array([-0.00515406, -0.00333362, -0.00149658,  0.00088152], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discriminative_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, init='uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Running through model to get predictions from the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s - loss: 0.6931\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s - loss: 0.6931\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s - loss: 0.6931\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s - loss: 0.6931\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s - loss: 0.6930\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s - loss: 0.6930\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s - loss: 0.6930\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s - loss: 0.6930\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s - loss: 0.6929\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s - loss: 0.6929\n"
     ]
    }
   ],
   "source": [
    "generator = get_generative_model()\n",
    "generator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "generator.fit(X, Y)\n",
    "generated_values = generator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49896124,  0.49937671,  0.49979225,  0.50020772],\n",
       "       [ 0.49896124,  0.49937671,  0.49979225,  0.50020772],\n",
       "       [ 0.49896124,  0.49937671,  0.49979225,  0.50020772]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2,  0.3,  0.4,  0.5],\n",
       "       [ 0.3,  0.4,  0.5,  0.6],\n",
       "       [ 0.2,  0.2,  0.3,  0.3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating input for the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = np.reshape(X, (3,4))\n",
    "# Y = np.reshape(Y, (3,4))\n",
    "# generated_input_to_discriminator = np.concatenate([X, generated_values], axis = 1)\n",
    "# generated_input_to_discriminator = np.reshape(generated_input_to_discriminator,(3,8))\n",
    "generated_input_to_discriminator = np.concatenate([X, generated_values], axis = 1) \n",
    "true_input_to_discriminator = np.concatenate([X, Y], axis = 1)\n",
    "\n",
    "#true_input_to_discriminator = np.reshape(true_input_to_discriminator,(3,8))\n",
    "#true_input_to_discriminator = Y\n",
    "\n",
    "Xdisc = np.concatenate((generated_input_to_discriminator, true_input_to_discriminator))\n",
    "Ydisc = [1] * len(generated_input_to_discriminator) + [0] * len(true_input_to_discriminator)\n",
    "new_data_disc = np.array([0.2,0.5,0.4, 0.2, 0.3, 0.6, 0.5, 0.3])\n",
    "#new_data_disc = np.reshape (new_data_disc, (2,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xdisc = Xdisc.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Running through model to get output from the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected dense_input_2 to have shape (None, 4) but got array with shape (6, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2bbd82ff661f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_discriminative_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXdisc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYdisc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdisc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1030\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m   1031\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected dense_input_2 to have shape (None, 4) but got array with shape (6, 8)"
     ]
    }
   ],
   "source": [
    "discriminator = get_discriminative_model()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "discriminator.fit (Xdisc, Ydisc)\n",
    "discriminator.predict(Xdisc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Connecting the discriminator to the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combined_model(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    # Here generator's output are arrays that are 8 numbers long\n",
    "    # Discriminator takes inpt that is 16 numbers long\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_containing_disciminator = combined_model(generator, discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTERNATIVE \n",
    "DISCRIMINATOR THAT TAKES THE GENERATORS OUTPUT IMMEDIATELY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_generative_model(hidden_neurons = 12, input_dim=4):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_neurons, activation='relu', input_dim = 4))\n",
    "    model.add(Dense(4, activation='sigmoid'))\n",
    "    #model.add(Reshape((4,1), input_shape=(1,4)))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discriminative_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, init='uniform', activation='relu'))\n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data = np.reshape(new_data, (1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = get_generative_model()\n",
    "generated_values = generator.predict(new_data)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_input = np.reshape(Y, (1,4))\n",
    "Xdisc = np.concatenate((generated_values, real_input))\n",
    "Ydisc = [1] * len(generated_values) + [0] * len(real_input)\n",
    "new_data = np.array([0.6, 0.6, 0.6, 0.6])\n",
    "new_data = np.reshape(new_data, (1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.49939361]], dtype=float32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = get_discriminative_model()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "discriminator.fit (Xdisc, Ydisc)\n",
    "discriminator.predict(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the discriminator with the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combined_model(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator_containing_disciminator = combined_model(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ydisc1 = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-358-162d170b862e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator_containing_disciminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYdisc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1031\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1034\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m   1035\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32m/home/madli/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "generator_containing_disciminator.fit(X, Ydisc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 8. Setting optimizers for the generator and the discriminator\n",
    "d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "generator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "generator_containing_disciminator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_losses(i):\n",
    "    epoch = 0\n",
    "    print ('Epoch:', epoch+1)\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for batchno in range(3):\n",
    "        inputdata = X\n",
    "        generated_audio = generator.predict(inputdata)\n",
    "        real_audio = Y\n",
    "        Xdisc = np.concatenate((real_audio, generated_audio))\n",
    "        Ydisc = [1] * len(real_audio) + [0] * len(generated_audio)\n",
    "        d_loss = discriminator.fit(Xdisc, Ydisc)  # later change to train on batch\n",
    "        d_losses.append(d_loss)\n",
    "        discriminator.trainable = False\n",
    "        g_loss = generator_containing_disciminator.fit(inputdata, len(real_audio))\n",
    "        #print g_loss\n",
    "    epoch =+ 1\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', 1)\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_losses(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        g_loss = generator_containing_disciminator.train_on_batch(inputdata, [1]*batch_size)\n",
    "        # take into account example data also. input audio - example of laugter - paper about images from Daniel. \n",
    "        \n",
    "        # 9.8 Calculate losses for the generator\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "        # I thought the discriminator was set to not trainable already in step 9.7??\n",
    "        discriminator.trainable = True\n",
    "        # Print how many batches have been trained on \n",
    "        sys.stdout.write(' + batch: ' + str(index+1) + '/' + str(n_batches) + '\\r')\n",
    "        # Everything from the buffer will be written in the terminal \n",
    "        sys.stdout.flush()\n",
    "    return d_losses, g_losses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
