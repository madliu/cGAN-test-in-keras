{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import os\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename  = \"/home/madli/Documents/Thesis/Input data/testset.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_np_array(np_arr):\n",
    "    np_arr = np_arr.astype(float)\n",
    "    np_arr = np_arr - np_arr.min()\n",
    "    np_arr = np_arr / (np_arr.max() - np_arr.min())\n",
    "    np_arr = (np_arr - 0.5) * 2\n",
    "    return np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_np_audio_to_sample_blocks(np_arr, frame_size):\n",
    "    block_list = []\n",
    "    total_values = np_arr.shape[0] # counts all of the numbers that are in the array\n",
    "    num_samples_so_far = 0\n",
    "    while(num_samples_so_far < total_values):\n",
    "        block = np_arr[num_samples_so_far:num_samples_so_far+frame_size]        \n",
    "# the following part adds 0-s to the end of the last block that is cut short\n",
    "        if(block.shape[0] < frame_size):\n",
    "            padding = np.zeros((frame_size - block.shape[0],))\n",
    "            block = np.concatenate((block, padding))\n",
    "        block_list.append(block)\n",
    "        num_samples_so_far += frame_size\n",
    "    return block_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_blocks_to_fft_blocks(blocks_time_domain):\n",
    "    fft_blocks = []\n",
    "    for block in blocks_time_domain:\n",
    "        fft_block = np.fft.fft(block) # Computing the one-dimensional discrete Fourier Transform.\n",
    "        new_block = np.concatenate((np.real(fft_block), np.imag(fft_block)))\n",
    "        fft_blocks.append(new_block) \n",
    "    return fft_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_training_example(np_arr, frame_size=4000, useTimeDomain=False):\n",
    "    data = normalize_np_array(np_arr)\n",
    "    x_t = convert_np_audio_to_sample_blocks(data, frame_size)\n",
    "    y_t = x_t[1:]\n",
    "    y_t.append(np.zeros(frame_size)) #Add special end block composed of all zeros\n",
    "    if useTimeDomain:\n",
    "        return x_t, y_t\n",
    "    X = time_blocks_to_fft_blocks(x_t)\n",
    "    Y = time_blocks_to_fft_blocks(y_t)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_chunks(files, max_files, useTimeDomain):\n",
    "    chunks_X = []\n",
    "    chunks_Y = []\n",
    "    \n",
    "    # For each file load its inputs and outputs\n",
    "    num_files = len(files)\n",
    "    if(num_files > max_files):\n",
    "        num_files = max_files\n",
    "    for file_idx in xrange(num_files):\n",
    "        filename = files[file_idx]\n",
    "        print 'Processing: ', (file_idx+1),'/',num_files\n",
    "        print 'Filename: ', filename\n",
    "        # The dimensions for X are []\n",
    "        rate, np_arr  = wav.read(filename)\n",
    "        X, Y = load_training_example(np_arr, frame_size, useTimeDomain=useTimeDomain)\n",
    "        \n",
    "        cur_seq = 0\n",
    "        total_seq = len(X)\n",
    "        \n",
    "        print \"Number of training samples is \"+ str(total_seq) # same as len(X)\n",
    "        print no_of_timesteps\n",
    "        while cur_seq + no_of_timesteps < total_seq: #Take 8 sample inputs from X at a time\n",
    "            chunks_X.append(X[cur_seq:cur_seq+no_of_timesteps])\n",
    "            chunks_Y.append(Y[cur_seq:cur_seq+no_of_timesteps])\n",
    "            cur_seq += no_of_timesteps\n",
    "    return chunks_X, chunks_Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
